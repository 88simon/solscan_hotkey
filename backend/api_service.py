#!/usr/bin/env python3
"""
============================================================================
Gun Del Sol - REST API Service
============================================================================
Description: Flask REST API service for Solana token analysis and
             wallet monitoring via AutoHotkey integration
Author: Generated by Claude Code
Version: 1.0 (Phase 1 - MVP)
============================================================================
"""

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from datetime import datetime
import json
import os
import re
import uuid
from threading import Thread
import csv
import io
from secure_logging import (
    log_info, log_success, log_warning, log_error,
    log_analysis_start, log_analysis_complete, log_token_save,
    log_address_registered, log_address_removed, sanitize_address
)
from debug_config import is_debug_enabled

# ============================================================================
# OPSEC: PRODUCTION MODE - Disable Sensitive Logging
# ============================================================================
# Debug logging is controlled by debug_config.py - change DEBUG_MODE there
# Note: helius_api.py handles print override, don't override here to avoid recursion
# ============================================================================

app = Flask(__name__)
# Enable CORS for Next.js frontend on localhost:3000
CORS(app, resources={r"/*": {"origins": "http://localhost:3000"}})

# Configuration
DATA_FILE = "monitored_addresses.json"
ANALYSIS_RESULTS_DIR = "analysis_results"
DEFAULT_THRESHOLD = 100  # Default SOL threshold for notifications

# Helius API key (read from environment or config file)
# Set via environment variable: set HELIUS_API_KEY=your-key-here
# Or create config.json with {"helius_api_key": "your-key-here"}
def load_api_key():
    """Load Helius API key from environment or config file"""
    # Try environment variable first
    api_key = os.environ.get('HELIUS_API_KEY')
    if api_key:
        return api_key

    # Try config.json
    config_file = 'config.json'
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
                return config.get('helius_api_key')
        except Exception as e:
            print(f"[WARN] Error loading config.json: {e}")

    print("[WARN] WARNING: No Helius API key found!")
    print("   Set HELIUS_API_KEY environment variable or create config.json")
    print("   Example config.json: {\"helius_api_key\": \"your-key-here\"}")
    return None

HELIUS_API_KEY = load_api_key()

# In-memory storage (backed by JSON file)
monitored_addresses = {}
analysis_jobs = {}  # job_id -> {status, result, error}

# Import Helius API and database
try:
    from helius_api import TokenAnalyzer, generate_axiom_export, generate_token_acronym, WebhookManager
    import analyzed_tokens_db as db
    helius_enabled = True
    print("[OK] Helius API module loaded")
    print("[OK] Database module loaded")
except ImportError as e:
    helius_enabled = False
    print(f"[WARN] Helius API not available: {e}")


def load_addresses():
    """Load monitored addresses from JSON file"""
    global monitored_addresses
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r') as f:
                monitored_addresses = json.load(f)
            print(f"[OK] Loaded {len(monitored_addresses)} monitored addresses from {DATA_FILE}")
        except Exception as e:
            print(f"[WARN] Error loading addresses: {e}")
            monitored_addresses = {}
    else:
        monitored_addresses = {}
        print(f"[WARN] No existing data file found. Starting fresh.")


def save_addresses():
    """Save monitored addresses to JSON file"""
    try:
        with open(DATA_FILE, 'w') as f:
            json.dump(monitored_addresses, f, indent=2)
        return True
    except Exception as e:
        print(f"[WARN] Error saving addresses: {e}")
        return False


def is_valid_solana_address(address):
    """
    Validate Solana address format
    - Must be 32-44 characters
    - Must only contain base58 characters (no 0, O, I, l)
    """
    if not address or not isinstance(address, str):
        return False

    # Length check
    if len(address) < 32 or len(address) > 44:
        return False

    # Base58 character check (excludes 0, O, I, l)
    base58_pattern = r'^[1-9A-HJ-NP-Za-km-z]+$'
    if not re.match(base58_pattern, address):
        return False

    return True


@app.route('/register', methods=['POST'])
def register_address():
    """
    Register a new Solana address for monitoring

    Expected JSON payload:
    {
        "address": "TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA",
        "timestamp": "20250101120000"  # optional
    }
    """
    try:
        data = request.get_json()

        if not data:
            return jsonify({"error": "No JSON data provided"}), 400

        address = data.get('address', '').strip()

        # Validate address
        if not is_valid_solana_address(address):
            return jsonify({"error": "Invalid Solana address format"}), 400

        # Check if already registered
        if address in monitored_addresses:
            return jsonify({
                "status": "already_registered",
                "message": f"Address already being monitored",
                "address": address,
                "registered_at": monitored_addresses[address]['registered_at']
            }), 200

        # Add new address with optional note
        note = data.get('note', '').strip() if data.get('note') else None

        monitored_addresses[address] = {
            "address": address,
            "registered_at": datetime.now().isoformat(),
            "threshold": DEFAULT_THRESHOLD,
            "total_notifications": 0,
            "last_notification": None,
            "note": note
        }

        # Save to file
        if save_addresses():
            log_address_registered(address)  # OPSEC: Sanitized logging
            return jsonify({
                "status": "success",
                "message": "Address registered for monitoring",
                "address": address,
                "threshold": DEFAULT_THRESHOLD,
                "total_monitored": len(monitored_addresses)
            }), 201
        else:
            return jsonify({"error": "Failed to save address"}), 500

    except Exception as e:
        print(f"[WARN] Error in /register: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/addresses', methods=['GET'])
def list_addresses():
    """List all monitored addresses"""
    return jsonify({
        "total": len(monitored_addresses),
        "addresses": list(monitored_addresses.values())
    }), 200


@app.route('/address/<address>', methods=['GET'])
def get_address(address):
    """Get details for a specific address"""
    if address in monitored_addresses:
        return jsonify(monitored_addresses[address]), 200
    else:
        return jsonify({"error": "Address not found"}), 404


@app.route('/address/<address>', methods=['DELETE'])
def remove_address(address):
    """Remove an address from monitoring"""
    if address in monitored_addresses:
        del monitored_addresses[address]
        save_addresses()
        print(f"[OK] Removed address: {address}")
        return jsonify({
            "status": "success",
            "message": "Address removed from monitoring",
            "address": address
        }), 200
    else:
        return jsonify({"error": "Address not found"}), 404


@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "running",
        "monitored_addresses": len(monitored_addresses),
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/address/<address>/note', methods=['PUT'])
def update_note(address):
    """Update note/tag for an address"""
    if address not in monitored_addresses:
        return jsonify({"error": "Address not found"}), 404

    try:
        data = request.get_json()
        note = data.get('note', '').strip() if data.get('note') else None

        monitored_addresses[address]['note'] = note
        save_addresses()
        print(f"[OK] Updated note for address: {address}")

        return jsonify({
            "status": "success",
            "message": "Note updated successfully",
            "address": address,
            "note": note
        }), 200

    except Exception as e:
        print(f"[WARN] Error updating note: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/import', methods=['POST'])
def import_addresses():
    """Import addresses from backup file"""
    try:
        data = request.get_json()
        imported = data.get('addresses', [])

        if not isinstance(imported, list):
            return jsonify({"error": "Invalid import format"}), 400

        added = 0
        skipped = 0

        for addr_data in imported:
            if isinstance(addr_data, dict):
                address = addr_data.get('address')
                if address and is_valid_solana_address(address):
                    if address not in monitored_addresses:
                        monitored_addresses[address] = {
                            "address": address,
                            "registered_at": addr_data.get('registered_at', datetime.now().isoformat()),
                            "threshold": addr_data.get('threshold', DEFAULT_THRESHOLD),
                            "total_notifications": addr_data.get('total_notifications', 0),
                            "last_notification": addr_data.get('last_notification'),
                            "note": addr_data.get('note')
                        }
                        added += 1
                    else:
                        skipped += 1

        save_addresses()
        print(f"[OK] Imported {added} addresses ({skipped} skipped as duplicates)")

        return jsonify({
            "status": "success",
            "message": f"Imported {added} addresses ({skipped} duplicates skipped)",
            "added": added,
            "skipped": skipped,
            "total": len(monitored_addresses)
        }), 200

    except Exception as e:
        print(f"[WARN] Error importing addresses: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/clear', methods=['POST'])
def clear_all():
    """Clear all monitored addresses (use with caution!)"""
    global monitored_addresses
    count = len(monitored_addresses)
    monitored_addresses = {}
    save_addresses()
    print(f"[WARN] Cleared all {count} monitored addresses")
    return jsonify({
        "status": "success",
        "message": f"Cleared {count} addresses",
        "total_monitored": 0
    }), 200


# ============================================================================
# Token Analysis Endpoints
# ============================================================================

def run_token_analysis(job_id, token_address, min_usd, time_window_hours):
    """Background worker function to analyze a token"""
    try:
        print(f"[Job {job_id}] === ANALYSIS STARTED (NEW CODE v7 - ON-CURVE FILTERING) ===")
        print(f"[Job {job_id}] Starting analysis for {token_address}")
        analysis_jobs[job_id]['status'] = 'processing'

        analyzer = TokenAnalyzer(HELIUS_API_KEY)
        result = analyzer.analyze_token(
            mint_address=token_address,
            min_usd=min_usd,
            time_window_hours=time_window_hours
        )

        # Extract token info with proper null handling
        token_info = result.get('token_info')
        if token_info is None:
            token_name = 'Unknown'
            token_symbol = 'UNK'
        else:
            metadata = token_info.get('onChainMetadata', {}).get('metadata', {})
            token_name = metadata.get('name', 'Unknown')
            token_symbol = metadata.get('symbol', 'UNK')

        # Generate acronym
        acronym = generate_token_acronym(token_name, token_symbol)

        # Generate Axiom export JSON
        axiom_export = generate_axiom_export(
            early_bidders=result.get('early_bidders', []),
            token_name=token_name,
            token_symbol=token_symbol,
            limit=10
        )

        # Convert datetime objects to strings for JSON serialization
        for bidder in result.get('early_bidders', []):
            if 'first_buy_time' in bidder and hasattr(bidder['first_buy_time'], 'isoformat'):
                bidder['first_buy_time'] = bidder['first_buy_time'].isoformat()

        # Save to database first to get the token_id
        try:
            token_id = db.save_analyzed_token(
                token_address=token_address,
                token_name=token_name,
                token_symbol=token_symbol,
                acronym=acronym,
                early_bidders=result.get('early_bidders', []),
                axiom_json=axiom_export,
                first_buy_timestamp=result.get('first_transaction_time'),
                credits_used=result.get('api_credits_used', 0)
            )
            print(f"[Job {job_id}] Saved to database (ID: {token_id})")
        except Exception as db_error:
            print(f"[Job {job_id}] Database save failed: {db_error}")
            raise  # Re-raise to prevent file creation if database save fails

        # ============================================================================
        # SENSITIVE DATA: Save files with ID-based naming
        # ============================================================================
        # WARNING: These files contain wallet addresses of early buyers you discovered.
        # This data reveals your trading strategy and should NEVER be committed to Git.
        # The analysis_results/ and axiom_exports/ directories are in .gitignore for your protection.
        # ============================================================================

        # Get file paths using database utility functions
        analysis_filepath = db.get_analysis_file_path(token_id, token_name, in_trash=False)
        axiom_filepath = db.get_axiom_file_path(token_id, acronym, in_trash=False)

        # Ensure directories exist
        os.makedirs(os.path.dirname(analysis_filepath), exist_ok=True)
        os.makedirs(os.path.dirname(axiom_filepath), exist_ok=True)

        # Save analysis results file
        with open(analysis_filepath, 'w') as f:
            json.dump(result, f, indent=2)

        # Save Axiom export file
        with open(axiom_filepath, 'w') as f:
            json.dump(axiom_export, f, indent=2)

        # Update database with file paths
        db.update_token_file_paths(token_id, analysis_filepath, axiom_filepath)

        # Store result filename for backwards compatibility
        result_filename = os.path.basename(analysis_filepath)

        # Store the result filename in the job for later retrieval
        analysis_jobs[job_id]['result_file'] = result_filename

        # Add Axiom export info to result
        result['axiom_export'] = {
            'wallets': axiom_export,
            'file': axiom_filepath,
            'filename': axiom_filename
        }
        result['acronym'] = acronym

        analysis_jobs[job_id]['status'] = 'completed'
        analysis_jobs[job_id]['result'] = result
        analysis_jobs[job_id]['completed_at'] = datetime.now().isoformat()
        analysis_jobs[job_id]['axiom_file'] = axiom_filepath

        print(f"[Job {job_id}] Analysis complete - found {result['total_unique_buyers']} early bidders")
        print(f"[Job {job_id}] Axiom export saved: {axiom_filepath}")

    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"[Job {job_id}] Analysis failed: {str(e)}")
        print(f"[Job {job_id}] Full traceback:\n{error_trace}")
        analysis_jobs[job_id]['status'] = 'failed'
        analysis_jobs[job_id]['error'] = str(e)
        analysis_jobs[job_id]['error_trace'] = error_trace


@app.route('/analyze/token', methods=['POST'])
def analyze_token():
    """
    Analyze a token to find early bidders

    Expected JSON payload:
    {
        "address": "TokenMintAddress...",
        "min_usd": 50,  # optional, default 50
        "time_window_hours": 999999  # optional, default 999999 (effectively unlimited)
    }
    """
    if not helius_enabled:
        return jsonify({
            "error": "Helius API not available. Install dependencies: pip install requests solana base58"
        }), 503

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No JSON data provided"}), 400

        token_address = data.get('address', '').strip()

        if not is_valid_solana_address(token_address):
            return jsonify({"error": "Invalid Solana address format"}), 400

        # Get analysis parameters
        min_usd = float(data.get('min_usd', 50))
        time_window_hours = int(data.get('time_window_hours', 999999))

        # Create analysis job
        job_id = str(uuid.uuid4())[:8]
        analysis_jobs[job_id] = {
            'job_id': job_id,
            'token_address': token_address,
            'status': 'queued',
            'min_usd': min_usd,
            'time_window_hours': time_window_hours,
            'created_at': datetime.now().isoformat(),
            'result': None,
            'error': None
        }

        # Start background analysis
        thread = Thread(target=run_token_analysis, args=(job_id, token_address, min_usd, time_window_hours))
        thread.daemon = True
        thread.start()

        print(f"[OK] Queued token analysis: {token_address} (Job ID: {job_id})")

        return jsonify({
            'status': 'queued',
            'job_id': job_id,
            'token_address': token_address,
            'min_usd': min_usd,
            'time_window_hours': time_window_hours,
            'results_url': f'/analysis/{job_id}'
        }), 202

    except Exception as e:
        print(f"[WARN] Error in /analyze/token: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/analysis/<job_id>', methods=['GET'])
def get_analysis(job_id):
    """Get analysis results by job ID"""
    if job_id not in analysis_jobs:
        return jsonify({"error": "Job not found"}), 404

    job = analysis_jobs[job_id]

    # If completed, ensure result is loaded
    if job['status'] == 'completed' and job['result'] is None:
        try:
            # Try to load from the token-named file first
            if 'result_file' in job:
                result_file = os.path.join(ANALYSIS_RESULTS_DIR, job['result_file'])
            else:
                # Fallback to old job_id naming for backwards compatibility
                result_file = os.path.join(ANALYSIS_RESULTS_DIR, f"{job_id}.json")

            with open(result_file, 'r') as f:
                job['result'] = json.load(f)
        except Exception as e:
            job['status'] = 'failed'
            job['error'] = f"Could not load results: {str(e)}"

    return jsonify(job), 200


@app.route('/analysis/<job_id>/csv', methods=['GET'])
def export_analysis_csv(job_id):
    """Export analysis results as CSV"""
    if job_id not in analysis_jobs:
        return jsonify({"error": "Job not found"}), 404

    job = analysis_jobs[job_id]

    if job['status'] != 'completed' or not job.get('result'):
        return jsonify({"error": "Analysis not completed or no results"}), 400

    try:
        # Create CSV in memory
        output = io.StringIO()
        writer = csv.writer(output)

        # Write header
        writer.writerow(['Wallet Address', 'First Buy Time', 'Total USD', 'Transaction Count', 'Average Buy USD'])

        # Write data
        for bidder in job['result'].get('early_bidders', []):
            writer.writerow([
                bidder['wallet_address'],
                bidder['first_buy_time'],
                f"${bidder['total_usd']:.2f}",
                bidder['transaction_count'],
                f"${bidder['average_buy_usd']:.2f}"
            ])

        # Prepare response
        output.seek(0)
        return send_file(
            io.BytesIO(output.getvalue().encode('utf-8')),
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'token_analysis_{job_id}.csv'
        )

    except Exception as e:
        return jsonify({"error": f"CSV export failed: {str(e)}"}), 500


@app.route('/analysis/<job_id>/axiom', methods=['GET'])
def download_axiom_export(job_id):
    """Download Axiom wallet tracker JSON"""
    if job_id not in analysis_jobs:
        return jsonify({"error": "Job not found"}), 404

    job = analysis_jobs[job_id]

    if job['status'] != 'completed' or not job.get('axiom_file'):
        return jsonify({"error": "Analysis not completed or Axiom export not available"}), 400

    try:
        axiom_filepath = job['axiom_file']
        if os.path.exists(axiom_filepath):
            return send_file(
                axiom_filepath,
                mimetype='application/json',
                as_attachment=True,
                download_name=os.path.basename(axiom_filepath)
            )
        else:
            return jsonify({"error": "Axiom export file not found"}), 404

    except Exception as e:
        return jsonify({"error": f"Download failed: {str(e)}"}), 500


@app.route('/analysis', methods=['GET'])
def list_analyses():
    """List all analysis jobs from database"""
    try:
        # Check if search query is provided
        search_query = request.args.get('search', '').strip()

        if search_query:
            # Search by token or wallet address
            tokens = db.search_tokens(search_query)
        else:
            # Get all analyzed tokens from database
            tokens = db.get_analyzed_tokens(limit=100)

        # Format as analysis jobs for compatibility with frontend
        jobs = []
        for token in tokens:
            jobs.append({
                'job_id': str(token['id']),
                'status': 'completed',
                'token_address': token['token_address'],
                'token_name': token['token_name'],
                'token_symbol': token['token_symbol'],
                'acronym': token['acronym'],
                'wallets_found': token['wallets_found'],
                'timestamp': token['analysis_timestamp'],
                'credits_used': token.get('last_analysis_credits', 0),
                'results_url': f'/analysis/{token["id"]}'
            })

        # Also include in-memory jobs (currently running) only if not searching
        if not search_query:
            for job_id, job_data in analysis_jobs.items():
                if job_data.get('status') != 'completed':
                    jobs.insert(0, job_data)  # Add running jobs at the top

        return jsonify({
            'total': len(jobs),
            'jobs': jobs
        }), 200
    except Exception as e:
        log_error(f"Failed to list analyses: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/multi-token-wallets', methods=['GET'])
def get_multi_token_wallets():
    """
    Get wallets that appear in multiple analyzed tokens.
    Query parameter: min_tokens (default: 2)
    """
    try:
        min_tokens = int(request.args.get('min_tokens', 2))
        wallets = db.get_multi_token_wallets(min_tokens=min_tokens)

        return jsonify({
            'total': len(wallets),
            'wallets': wallets
        }), 200
    except Exception as e:
        log_error(f"Failed to get multi-token wallets: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/wallets/<wallet_address>/tags', methods=['GET', 'POST', 'DELETE'])
def manage_wallet_tags(wallet_address):
    """
    Manage tags for a wallet address.
    GET: Get all tags for a wallet
    POST: Add a tag to a wallet (expects JSON: {"tag": "tagname", "is_kol": boolean})
    DELETE: Remove a tag from a wallet (expects JSON: {"tag": "tagname"})
    """
    try:
        if request.method == 'GET':
            tags = db.get_wallet_tags(wallet_address)
            return jsonify({'wallet_address': wallet_address, 'tags': tags}), 200

        elif request.method == 'POST':
            data = request.get_json()
            if not data or 'tag' not in data:
                return jsonify({'error': 'Tag is required'}), 400

            tag = data['tag'].strip()
            if not tag:
                return jsonify({'error': 'Tag cannot be empty'}), 400

            is_kol = data.get('is_kol', False)
            added = db.add_wallet_tag(wallet_address, tag, is_kol)
            if added:
                return jsonify({
                    'message': 'Tag added successfully',
                    'wallet_address': wallet_address,
                    'tag': tag,
                    'is_kol': is_kol
                }), 201
            else:
                return jsonify({
                    'message': 'Tag already exists',
                    'wallet_address': wallet_address,
                    'tag': tag
                }), 200

        elif request.method == 'DELETE':
            data = request.get_json()
            if not data or 'tag' not in data:
                return jsonify({'error': 'Tag is required'}), 400

            tag = data['tag'].strip()
            removed = db.remove_wallet_tag(wallet_address, tag)
            if removed:
                return jsonify({
                    'message': 'Tag removed successfully',
                    'wallet_address': wallet_address,
                    'tag': tag
                }), 200
            else:
                return jsonify({
                    'message': 'Tag not found',
                    'wallet_address': wallet_address,
                    'tag': tag
                }), 404

    except Exception as e:
        log_error(f"Failed to manage wallet tags: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/tags', methods=['GET'])
def get_all_tags():
    """Get all unique tags across all wallets"""
    try:
        tags = db.get_all_tags()
        return jsonify({'tags': tags}), 200
    except Exception as e:
        log_error(f"Failed to get tags: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/tags/<tag>/wallets', methods=['GET'])
def get_wallets_by_tag(tag):
    """Get all wallets with a specific tag"""
    try:
        wallets = db.get_wallets_by_tag(tag)
        return jsonify({'tag': tag, 'wallets': wallets}), 200
    except Exception as e:
        log_error(f"Failed to get wallets by tag: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/codex', methods=['GET'])
def get_codex():
    """Get all wallets that have tags (Codex)"""
    try:
        wallets = db.get_all_tagged_wallets()
        return jsonify({'wallets': wallets}), 200
    except Exception as e:
        log_error(f"Failed to get Codex: {e}")
        return jsonify({'error': str(e)}), 500


# ============================================================================
# Webhook Management Endpoints
# ============================================================================

@app.route('/webhooks/create', methods=['POST'])
def create_wallet_webhook():
    """
    Create a webhook to monitor wallet addresses

    Expected JSON payload:
    {
        "token_id": 123,  # Database token ID
        "webhook_url": "http://yourserver.com/webhook/callback"  # optional, defaults to this service
    }
    """
    if not helius_enabled:
        return jsonify({"error": "Helius API not available"}), 503

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No JSON data provided"}), 400

        token_id = data.get('token_id')
        if not token_id:
            return jsonify({"error": "token_id is required"}), 400

        # Get token details from database
        token_details = db.get_token_details(token_id)
        if not token_details:
            return jsonify({"error": "Token not found"}), 404

        # Get wallet addresses
        wallets = token_details.get('wallets', [])
        if not wallets:
            return jsonify({"error": "No wallets found for this token"}), 400

        wallet_addresses = [w['wallet_address'] for w in wallets]

        # Use provided webhook URL or default to this service
        webhook_callback_url = data.get('webhook_url', f"http://localhost:5001/webhooks/callback")

        # Create webhook using WebhookManager
        webhook_manager = WebhookManager(HELIUS_API_KEY)
        result = webhook_manager.create_webhook(
            webhook_url=webhook_callback_url,
            wallet_addresses=wallet_addresses,
            transaction_types=["TRANSFER", "SWAP"]
        )

        webhook_id = result.get('webhookID')

        # Update database with webhook ID
        try:
            # Note: This would require adding an update function to database.py
            # For now, we'll just return the webhook ID
            print(f"[Webhook] Created webhook {webhook_id} for token ID {token_id}")
        except Exception as e:
            print(f"[Webhook] Could not update database: {e}")

        return jsonify({
            "status": "success",
            "webhook_id": webhook_id,
            "token_id": token_id,
            "wallets_monitored": len(wallet_addresses),
            "webhook_details": result
        }), 201

    except Exception as e:
        print(f"[WARN] Error creating webhook: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/webhooks/list', methods=['GET'])
def list_webhooks():
    """List all active webhooks"""
    if not helius_enabled:
        return jsonify({"error": "Helius API not available"}), 503

    try:
        webhook_manager = WebhookManager(HELIUS_API_KEY)
        webhooks = webhook_manager.list_webhooks()

        return jsonify({
            "total": len(webhooks),
            "webhooks": webhooks
        }), 200

    except Exception as e:
        print(f"[WARN] Error listing webhooks: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/webhooks/<webhook_id>', methods=['GET'])
def get_webhook_details(webhook_id):
    """Get details of a specific webhook"""
    if not helius_enabled:
        return jsonify({"error": "Helius API not available"}), 503

    try:
        webhook_manager = WebhookManager(HELIUS_API_KEY)
        webhook = webhook_manager.get_webhook(webhook_id)

        return jsonify(webhook), 200

    except Exception as e:
        print(f"[WARN] Error getting webhook: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/webhooks/<webhook_id>', methods=['DELETE'])
def delete_webhook(webhook_id):
    """Delete a webhook"""
    if not helius_enabled:
        return jsonify({"error": "Helius API not available"}), 503

    try:
        webhook_manager = WebhookManager(HELIUS_API_KEY)
        webhook_manager.delete_webhook(webhook_id)

        return jsonify({
            "status": "success",
            "message": f"Webhook {webhook_id} deleted"
        }), 200

    except Exception as e:
        print(f"[WARN] Error deleting webhook: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/webhooks/callback', methods=['POST'])
def webhook_callback():
    """
    Receive webhook notifications from Helius.
    This endpoint processes wallet activity events.
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No data provided"}), 400

        # Helius sends an array of transactions
        transactions = data if isinstance(data, list) else [data]

        for tx in transactions:
            # Extract transaction details
            signature = tx.get('signature')
            timestamp = tx.get('timestamp')
            tx_type = tx.get('type')
            description = tx.get('description', '')

            # Get account keys involved
            account_data = tx.get('accountData', [])

            # Extract SOL and token transfers
            native_transfers = tx.get('nativeTransfers', [])
            token_transfers = tx.get('tokenTransfers', [])

            # Process each wallet involved in the transaction
            for transfer in native_transfers + token_transfers:
                wallet_address = transfer.get('fromUserAccount') or transfer.get('toUserAccount')

                if not wallet_address:
                    continue

                # Determine activity details
                if transfer in native_transfers:
                    sol_amount = transfer.get('amount', 0) / 1e9
                    token_amount = 0.0
                    recipient = transfer.get('toUserAccount')
                else:
                    sol_amount = 0.0
                    token_amount = float(transfer.get('tokenAmount', 0))
                    recipient = transfer.get('toUserAccount')

                # Save to database
                try:
                    db.save_wallet_activity(
                        wallet_address=wallet_address,
                        transaction_signature=signature,
                        timestamp=datetime.fromtimestamp(timestamp).isoformat() if timestamp else None,
                        activity_type=tx_type,
                        description=description,
                        sol_amount=sol_amount,
                        token_amount=token_amount,
                        recipient_address=recipient
                    )
                    print(f"[Webhook] Saved activity for wallet {wallet_address[:8]}...")
                except Exception as e:
                    print(f"[Webhook] Failed to save activity: {e}")

        return jsonify({"status": "success", "processed": len(transactions)}), 200

    except Exception as e:
        print(f"[WARN] Webhook callback error: {e}")
        return jsonify({"error": str(e)}), 500


# ============================================================================
# Root Endpoint
# ============================================================================

@app.route('/')
def root():
    """API root endpoint with service information"""
    return jsonify({
        'status': 'ok',
        'service': 'Gun Del Sol API',
        'version': '1.0',
        'message': 'REST API for Solana token analysis',
        'endpoints': {
            'health': '/health',
            'tokens': '/api/tokens/history',
            'analysis': '/analysis',
            'tags': '/tags',
            'multi_token_wallets': '/multi-token-wallets'
        }
    })


# ============================================================================
# Token History API Endpoints
# ============================================================================

@app.route('/api/tokens/history', methods=['GET'])
def get_token_history():
    """Get list of analyzed tokens from database"""
    try:
        limit = request.args.get('limit', 50, type=int)
        tokens = db.get_analyzed_tokens(limit=limit)

        # Calculate total wallets
        total_wallets = sum(token.get('wallets_found', 0) for token in tokens)

        return jsonify({
            'total': len(tokens),
            'total_wallets': total_wallets,
            'tokens': tokens
        }), 200

    except Exception as e:
        print(f"[WARN] Error in /api/tokens/history: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/tokens/<int:token_id>', methods=['GET'])
def get_token_by_id(token_id):
    """Get detailed token information including wallets"""
    try:
        token_details = db.get_token_details(token_id)

        if not token_details:
            return jsonify({"error": "Token not found"}), 404

        return jsonify(token_details), 200

    except Exception as e:
        print(f"[WARN] Error in /api/tokens/{token_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/tokens/<int:token_id>/history', methods=['GET'])
def get_token_analysis_history(token_id):
    """Get all analysis runs for a token with their wallets"""
    try:
        history = db.get_token_analysis_history(token_id)

        if not history:
            return jsonify({"error": "No analysis history found"}), 404

        return jsonify({
            "token_id": token_id,
            "total_runs": len(history),
            "runs": history
        }), 200

    except Exception as e:
        print(f"[WARN] Error getting analysis history for token {token_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/tokens/<int:token_id>', methods=['DELETE'])
def delete_token_by_id(token_id):
    """Soft delete an analyzed token (moves to trash)"""
    try:
        success = db.soft_delete_token(token_id)

        if not success:
            return jsonify({"error": "Token not found"}), 404

        print(f"[OK] Soft deleted token ID {token_id} via API")
        return jsonify({
            "status": "success",
            "message": f"Token {token_id} moved to trash"
        }), 200

    except Exception as e:
        print(f"[WARN] Error deleting token {token_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/tokens/trash', methods=['GET'])
def get_trash():
    """Get all soft-deleted tokens (trash)"""
    try:
        tokens = db.get_deleted_tokens()
        total = len(tokens)

        return jsonify({
            'tokens': tokens,
            'total': total
        }), 200

    except Exception as e:
        log_error(f"Failed to get trash: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/tokens/<int:token_id>/restore', methods=['POST'])
def restore_token_by_id(token_id):
    """Restore a soft-deleted token from trash"""
    try:
        success = db.restore_token(token_id)

        if not success:
            return jsonify({"error": "Token not found in trash"}), 404

        print(f"[OK] Restored token ID {token_id} via API")
        return jsonify({
            "status": "success",
            "message": f"Token {token_id} restored successfully"
        }), 200

    except Exception as e:
        print(f"[WARN] Error restoring token {token_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/tokens/<int:token_id>/permanent', methods=['DELETE'])
def permanent_delete_token_by_id(token_id):
    """Permanently delete a token and all associated data (cannot be undone)"""
    try:
        success = db.permanent_delete_token(token_id)

        if not success:
            return jsonify({"error": "Token not found"}), 404

        print(f"[OK] Permanently deleted token ID {token_id} via API")
        return jsonify({
            "status": "success",
            "message": f"Token {token_id} permanently deleted"
        }), 200

    except Exception as e:
        print(f"[WARN] Error permanently deleting token {token_id}: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/debug/config', methods=['GET'])
def get_debug_config():
    """Get debug configuration for client-side (JavaScript)"""
    from debug_config import get_debug_js_flag
    return jsonify({"debug": get_debug_js_flag()}), 200


if __name__ == '__main__':
    print("=" * 70)
    print("Gun Del Sol - REST API Service")
    print("=" * 70)
    print(f"Starting Flask server on http://localhost:5001")
    print(f"Data file: {DATA_FILE}")
    print(f"Default threshold: {DEFAULT_THRESHOLD} SOL")
    print("-" * 70)

    # Load existing addresses
    load_addresses()

    print("-" * 70)
    print("Available endpoints:")
    print("  GET    /                           - Web Dashboard")
    print("  POST   /register                   - Register new address")
    print("  GET    /addresses                  - List all addresses")
    print("  GET    /address/<addr>             - Get address details")
    print("  DELETE /address/<addr>             - Remove address")
    print("  PUT    /address/<addr>/note        - Update address note")
    print("  POST   /import                     - Import addresses from backup")
    print("  GET    /health                     - Health check")
    print("  POST   /clear                      - Clear all addresses")
    print()
    print("  POST   /analyze/token              - Analyze token for early bidders")
    print("  GET    /analysis                   - List all analysis jobs")
    print("  GET    /analysis/<job_id>          - Get analysis status/results")
    print("  GET    /analysis/<job_id>/results  - View results in browser")
    print("  GET    /analysis/<job_id>/csv      - Export results as CSV")
    print("-" * 70)
    if helius_enabled:
        print("[OK] Helius API enabled - Token analysis ready")
    else:
        print("[WARN] Helius API disabled - Run: pip install requests solana base58")
    print("-" * 70)
    print("\n>> Flask API:   http://localhost:5001")
    print(">> Next.js Web: http://localhost:3000")
    print("\nPress Ctrl+C to stop the server")
    print("=" * 70)
    print()

    # Run server with auto-reload on code changes
    app.run(host='localhost', port=5001, debug=True, use_reloader=True)